{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Guide: \n",
    "\n",
    "This Quickstart Guide presents a simple example of **ocean data challenge** for mapping the Sea Surface Height from sparse observations. \n",
    "\n",
    "The methodology is based on an Observing System Simulation Experiment (OSSE). The inputs data represent altimeter observations extracted from a realistic high-resolution ocean model simulation (NATL60). A simple mapping algorithm (Optimal Interpolation) is used to produce the reconstructed SSH field from the sparse observations. Finally, a comparison between the reconstructed and the reference SSH fields is done to quantify the reconstruction scores.\n",
    "\n",
    "Three experiments are carried out with <font color=grey> **Experiment 3**</font>: demo. of reconstruction with <font color=grey> **1 SWOT altimeter**</font>\n",
    "\n",
    "The notebook is structured as follows:\n",
    "\n",
    "    1) downloading the data\n",
    "    2) Setup configuration of the interpolation\n",
    "    3) Run the DINAE experiment\n",
    "    4) Plot some figures and interpolation scores\n",
    "\n",
    "This quickstart guide take approx. 30 min to run on a PC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DINAE libraries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrateur/anaconda3/envs/conda-forge/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from DINAE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:38729\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>16.63 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:38729' processes=4 cores=8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "cluster = dask.distributed.LocalCluster()\n",
    "client = dask.distributed.Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- DOWNLOADING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When downloading the 3 datasets (ref, data & oi), be sure that the names of the files will be the same than those specified in the config.yml file used to define the setup configuration. If no, please modify the config.yml file or change the downloaded file names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download Nature run SSH for mapping evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.eu-central-1.wasabisys.com/melody/REF.nc -O \"ref.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download Synthetic SSH observation for OI mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.eu-central-1.wasabisys.com/melody/DATA.nc -O \"data.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Download OI mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.eu-central-1.wasabisys.com/melody/OI.nc -O \"oi.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- SETUP CONFIGURATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description of the parameters\n",
    "domain   = \"GULFSTREAM\"\n",
    "opt      = \"nadirswot\"\n",
    "lag      = \"0\"             \n",
    "type_obs = \"mod\"       # mod/obs\n",
    "\n",
    "# main code\n",
    "parser = argparse.ArgumentParser()\n",
    "with open('config.yml', 'rb') as f:\n",
    "    conf = yaml.load(f.read())\n",
    "# list of global parameters (comments to add)\n",
    "fileMod                 = conf['path_files']['fileMod']\n",
    "fileOI                  = conf['path_files']['fileOI']\n",
    "fileObs                 = conf['path_files']['fileObs']\n",
    "flagTrWMissingData      = conf['data_options']['flagTrWMissingData'] \n",
    "flagloadOIData          = conf['data_options']['flagloadOIData']\n",
    "include_covariates      = conf['data_options']['include_covariates']\n",
    "lfile_cov               = conf['data_options']['lfile_cov']\n",
    "lname_cov               = conf['data_options']['lname_cov']\n",
    "lid_cov                 = conf['data_options']['lid_cov']   \n",
    "N_cov                   = ifelse(include_covariates==True,len(lid_cov),0)\n",
    "size_tw                 = conf['data_options']['size_tw'] \n",
    "Wsquare                 = conf['data_options']['Wsquare']\n",
    "Nsquare                 = conf['data_options']['Nsquare']\n",
    "DimAE                   = conf['NN_options']['DimAE']\n",
    "flagAEType              = conf['NN_options']['flagAEType']\n",
    "sigNoise                = conf['data_options']['sigNoise']\n",
    "flagTrOuputWOMissingData= conf['data_options']['flagTrOuputWOMissingData']\n",
    "stdMask                 = conf['data_options']['stdMask']\n",
    "dropout                 = conf['data_options']['dropout']\n",
    "wl2                     = conf['data_options']['wl2']\n",
    "batch_size              = conf['training_params']['batch_size']\n",
    "NbEpoc                  = conf['training_params']['NbEpoc']\n",
    "Niter                   = conf['training_params']['Niter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- CREATE OUTPUT DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flagAEType==1:\n",
    "    suf1 = \"ConvAE\"\n",
    "if flagAEType==2:\n",
    "    suf1 = \"GENN\"\n",
    "if flagTrWMissingData==0:\n",
    "    suf2 = \"womissing\"\n",
    "elif flagTrWMissingData==1:\n",
    "    suf2 = \"wmissing\"\n",
    "else:\n",
    "    suf2 = \"wwmissing\"\n",
    "suf3 = \"FP\"\n",
    "suf4 = ifelse(include_covariates==True,\"w\"+'-'.join(lid_cov),\"wocov\")\n",
    "dirSAVE = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- RUN EXPERIMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) .... Load SSH dataset (training data): /data/dataset_nadir_0d_swot.nc\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/ref/NATL60-CJM165_GULFSTREAM_ssh_y2013.1y.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ca09bf93ac2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m## 1) *** Read the data ***\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgenFilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_missing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanTr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdTr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_missing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlday_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_OI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_OI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobParams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Bureau/2020a_IMT_SSH_mapping_NATL60/DINAE/mods/import_Datasets.py\u001b[0m in \u001b[0;36mimport_Data\u001b[0;34m(dict_global_Params, type_obs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1) .... Load SSH dataset (training data): \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfileObs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mnc_data_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileMod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mnc_data_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileObs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mx_orig\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mImputing_NaN_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc_data_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ssh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindLat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindLon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/ref/NATL60-CJM165_GULFSTREAM_ssh_y2013.1y.nc'"
     ]
    }
   ],
   "source": [
    "# push all global parameters in a list\n",
    "def createGlobParams(params):\n",
    "    return dict(((k, eval(k)) for k in params))\n",
    "list_globParams=['domain','fileMod','fileObs','fileOI',\\\n",
    "'include_covariates','N_cov','lfile_cov','lid_cov','lname_cov',\\\n",
    "'flagTrOuputWOMissingData','flagTrWMissingData',\\\n",
    "'flagloadOIData','size_tw','Wsquare',\\\n",
    "'Nsquare','DimAE','flagAEType',\\\n",
    "'sigNoise','stdMask','dropout','wl2','batch_size',\\\n",
    "'NbEpoc','Niter','dirSAVE','suf1','suf2','suf3','suf4']\n",
    "globParams = createGlobParams(list_globParams)   \n",
    "\n",
    "## 1) *** Read the data ***\n",
    "genFilename, x_train, y_train, mask_train, gt_train, x_train_missing, meanTr, stdTr,\\\n",
    "x_test, y_test, mask_test, gt_test, x_test_missing, lday_test, x_train_OI, x_test_OI = import_Data(globParams,type_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Define the NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genFilename, encoder, decoder, model_AE, DIMCAE = define_Models(globParams,genFilename,x_train,mask_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Train DINAE with Fixed-Point solver    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_solver(globParams,genFilename,x_train,x_train_missing,mask_train,gt_train,meanTr,stdTr,\\\n",
    "          x_test,x_test_missing,mask_test,gt_test,lday_test,x_train_OI,x_test_OI,encoder,decoder,model_AE,DIMCAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - POSTPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Plot figures    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Compute RMSE and spectrum   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
