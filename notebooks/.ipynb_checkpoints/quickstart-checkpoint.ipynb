{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Guide: \n",
    "\n",
    "This Quickstart Guide presents a simple example of **ocean data challenge** for mapping the Sea Surface Height from sparse observations. \n",
    "\n",
    "The methodology is based on an Observing System Simulation Experiment (OSSE). The inputs data represent altimeter observations extracted from a realistic high-resolution ocean model simulation (NATL60). A simple mapping algorithm (Optimal Interpolation) is used to produce the reconstructed SSH field from the sparse observations. Finally, a comparison between the reconstructed and the reference SSH fields is done to quantify the reconstruction scores.\n",
    "\n",
    "Three experiments are carried out with <font color=grey> **Experiment 3**</font>: demo. of reconstruction with <font color=grey> **1 SWOT altimeter**</font>\n",
    "\n",
    "The notebook is structured as follows:\n",
    "\n",
    "    1) downloading the data\n",
    "    2) Setup configuration of the interpolation\n",
    "    3) Run the DINAE experiment\n",
    "    4) Plot some figures and interpolation scores\n",
    "\n",
    "This quickstart guide take approx. 30 min to run on a PC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DINAE libraries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrateur/anaconda3/envs/conda-forge/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from DINAE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:46419\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>4.16 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:46419' processes=1 cores=2>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "cluster = dask.distributed.LocalCluster()\n",
    "cluster.scale(1)\n",
    "client = dask.distributed.Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- DOWNLOADING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When downloading the 3 datasets (ref, data & oi), be sure that the names of the files will be the same than those specified in the config.yml file used to define the setup configuration. If no, please modify the config.yml file or change the downloaded file names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download Nature run SSH for mapping evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-10 14:01:04--  https://s3.eu-central-1.wasabisys.com/melody/ref.nc\n",
      "Résolution de s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)… 130.117.252.13, 130.117.252.10, 130.117.252.17, ...\n",
      "Connexion à s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)|130.117.252.13|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 118012432 (113M) [application/x-netcdf]\n",
      "Enregistre : «ref.nc»\n",
      "\n",
      "ref.nc              100%[===================>] 112,54M  8,45MB/s    ds 16s     \n",
      "\n",
      "2020-09-10 14:01:20 (6,95 MB/s) - «ref.nc» enregistré [118012432/118012432]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget https://s3.eu-central-1.wasabisys.com/melody/ref.nc -O \"ref.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download Synthetic SSH observation for OI mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-10 14:01:20--  https://s3.eu-central-1.wasabisys.com/melody/data.nc\n",
      "Résolution de s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)… 130.117.252.11, 130.117.252.16, 130.117.252.12, ...\n",
      "Connexion à s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)|130.117.252.11|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 708322336 (676M) [application/x-netcdf]\n",
      "Enregistre : «data.nc»\n",
      "\n",
      "data.nc             100%[===================>] 675,51M  5,97MB/s    ds 1m 55s  \n",
      "\n",
      "2020-09-10 14:03:15 (5,89 MB/s) - «data.nc» enregistré [708322336/708322336]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget https://s3.eu-central-1.wasabisys.com/melody/data.nc -O \"data.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Download OI mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-10 14:03:15--  https://s3.eu-central-1.wasabisys.com/melody/oi.nc\n",
      "Résolution de s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)… 130.117.252.10, 130.117.252.16, 130.117.252.17, ...\n",
      "Connexion à s3.eu-central-1.wasabisys.com (s3.eu-central-1.wasabisys.com)|130.117.252.10|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 235956168 (225M) [application/x-netcdf]\n",
      "Enregistre : «oi.nc»\n",
      "\n",
      "oi.nc               100%[===================>] 225,02M  9,34MB/s    ds 31s     \n",
      "\n",
      "2020-09-10 14:03:46 (7,35 MB/s) - «oi.nc» enregistré [235956168/235956168]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget https://s3.eu-central-1.wasabisys.com/melody/oi.nc -O \"oi.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- SETUP CONFIGURATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description of the parameters\n",
    "domain   = \"GULFSTREAM\"\n",
    "opt      = \"nadirswot\"\n",
    "lag      = \"0\"             \n",
    "type_obs = \"mod\"       # mod/obs\n",
    "\n",
    "# main code\n",
    "parser = argparse.ArgumentParser()\n",
    "with open('config.yml', 'rb') as f:\n",
    "    conf = yaml.load(f.read())\n",
    "    \n",
    "# list of global parameters (comments to add)\n",
    "fileMod                 = conf['path_files']['fileMod']\n",
    "fileOI                  = conf['path_files']['fileOI']\n",
    "fileObs                 = conf['path_files']['fileObs']\n",
    "flagTrWMissingData      = conf['data_options']['flagTrWMissingData'] \n",
    "flagloadOIData          = conf['data_options']['flagloadOIData']\n",
    "include_covariates      = conf['data_options']['include_covariates']\n",
    "lfile_cov               = conf['data_options']['lfile_cov']\n",
    "lname_cov               = conf['data_options']['lname_cov']\n",
    "lid_cov                 = conf['data_options']['lid_cov']   \n",
    "N_cov                   = ifelse(include_covariates==True,len(lid_cov),0)\n",
    "size_tw                 = conf['data_options']['size_tw'] \n",
    "Wsquare                 = conf['data_options']['Wsquare']\n",
    "Nsquare                 = conf['data_options']['Nsquare']\n",
    "DimAE                   = conf['NN_options']['DimAE']\n",
    "flagAEType              = conf['NN_options']['flagAEType']\n",
    "sigNoise                = conf['data_options']['sigNoise']\n",
    "flagTrOuputWOMissingData= conf['data_options']['flagTrOuputWOMissingData']\n",
    "stdMask                 = conf['data_options']['stdMask']\n",
    "dropout                 = conf['data_options']['dropout']\n",
    "start_eval_index        = conf['data_options']['start_eval_index']\n",
    "end_eval_index          = conf['data_options']['end_eval_index']\n",
    "start_train_index       = conf['data_options']['start_train_index']\n",
    "end_train_index         = conf['data_options']['end_train_index']\n",
    "wl2                     = conf['data_options']['wl2']\n",
    "batch_size              = conf['training_params']['batch_size']\n",
    "NbEpoc                  = conf['training_params']['NbEpoc']\n",
    "Niter                   = conf['training_params']['Niter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- CREATE OUTPUT DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flagAEType==1:\n",
    "    suf1 = \"ConvAE\"\n",
    "else:\n",
    "    suf1 = \"GENN\"\n",
    "    \n",
    "if flagTrWMissingData==0:\n",
    "    suf2 = \"womissing\"  \n",
    "elif flagTrWMissingData==1:\n",
    "    suf2 = \"wmissing\"\n",
    "else:\n",
    "    suf2 = \"wwmissing\"\n",
    "    \n",
    "suf3 = \"FP\"\n",
    "suf4 = ifelse(include_covariates==True,\"w\"+'-'.join(lid_cov),\"wocov\")\n",
    "dirSAVE = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- RUN EXPERIMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) .... Load SSH dataset (training data): data.nc\n",
      ".... Load OI SSH dataset (training data): oi.nc\n",
      ".... Load OI dataset (training data): oi.nc\n"
     ]
    }
   ],
   "source": [
    "# push all global parameters in a list\n",
    "def createGlobParams(params):\n",
    "    return dict(((k, eval(k)) for k in params))\n",
    "\n",
    "list_globParams=['domain','fileMod','fileObs','fileOI',\\\n",
    "'include_covariates','N_cov','lfile_cov','lid_cov','lname_cov',\\\n",
    "'flagTrOuputWOMissingData','flagTrWMissingData',\\\n",
    "'flagloadOIData','size_tw','Wsquare',\\\n",
    "'Nsquare','DimAE','flagAEType',\\\n",
    "'sigNoise','stdMask','dropout','wl2',\\\n",
    "'start_eval_index','end_eval_index',\\\n",
    "'start_train_index','end_train_index',\\\n",
    "'batch_size','NbEpoc','Niter',\\\n",
    "'dirSAVE','suf1','suf2','suf3','suf4']\n",
    "globParams = createGlobParams(list_globParams)   \n",
    "\n",
    "## 1) *** Read the data ***\n",
    "genFilename, x_train, y_train, mask_train, gt_train, x_train_missing, meanTr, stdTr,\\\n",
    "x_test, y_test, mask_test, gt_test, x_test_missing, lday_test, x_train_OI, x_test_OI = import_Data(globParams,type_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Define the NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genFilename, encoder, decoder, model_AE, DIMCAE = define_Models(globParams,genFilename,x_train,mask_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Train DINAE with Fixed-Point solver    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_solver(globParams,genFilename,x_train,x_train_missing,mask_train,gt_train,meanTr,stdTr,\\\n",
    "          x_test,x_test_missing,mask_test,gt_test,lday_test,x_train_OI,x_test_OI,encoder,decoder,model_AE,DIMCAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - POSTPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Plot figures    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from utils.plot_maps import *\n",
    "from utils.fourier_spectra import *\n",
    "from utils.export_NetCDF import *\n",
    "\n",
    "# get lon, lat and extent \n",
    "lon = xr.open_dataset(\"ref.nc\").lon.values[:200]\n",
    "lat = xr.open_dataset(\"ref.nc\").lat.values[:200]\n",
    "time = xr.open_dataset(\"ref.nc\").time.values[start_eval_index:end_eval_index]\n",
    "extent = [np.min(lon),np.max(lon),np.min(lat),np.max(lat)]\n",
    "\n",
    "# read the reference NetCDF file\n",
    "GT = xr.open_dataset(\"ref.nc\").ssh.values[start_eval_index:end_eval_index]\n",
    "# read the oi NetCDF file\n",
    "itrp_OI = xr.open_dataset(\"oi.nc\").ssh_mod.values[start_eval_index:end_eval_index]\n",
    "# export the itrp pickle file as NetCDF\n",
    "ifile='saved_path_'+str(Niter).zfill(3)+'_FP_GENN_wwmissing.pickle'\n",
    "ofile='FP_GENN.nc'\n",
    "export_NetCDF(ifile,ofile,lon,lat,time)\n",
    "# read the itrp NetCDF file\n",
    "itrp_FP_GENN = xr.open_dataset(\"FP_GENN.nc\").FP_GENN.values\n",
    "\n",
    "i = 25 # index of the evaluation day to plot\n",
    "gt           = GT[i,:200,:200]\n",
    "Grad_gt      = Gradient(gt,2)\n",
    "OI          = itrp_OI[i,:200,:200]\n",
    "Grad_OI      = Gradient(OI,2)\n",
    "FP_GENN      = itrp_FP_GENN[i,:200,:200]\n",
    "Grad_FP_GENN = Gradient(FP_GENN,2)\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(40,25),squeeze=False,\n",
    "                        subplot_kw=dict(projection=ccrs.PlateCarree(central_longitude=0.0)))\n",
    "\n",
    "vmin = np.nanmin(Grad_gt) ; vmax = np.nanmax(Grad_gt)\n",
    "cmap=\"viridis\"\n",
    "plot(ax,0,0,lon,lat,Grad_gt, r\"$\\nabla_{GT}$\",\\\n",
    "             extent=extent,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "plot(ax,0,1,lon,lat,Grad_OI, r\"$\\nabla_{OI}$\",\\\n",
    "             extent=extent,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "plot(ax,0,2,lon,lat,Grad_FP_GENN, r\"$\\nabla_{FP-GENN}$\",\\\n",
    "             extent=extent,cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Compute RMSE and spectrum   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmse_OI=np.zeros(len(GT))\n",
    "nrmse_FP_GENN=np.zeros(len(GT))\n",
    "\n",
    "for i in range(0,len(GT)):\n",
    "    gt           = GT[i,:200,:200]\n",
    "    OI_          = itrp_OI[i,:200,:200]\n",
    "    FP_GENN      = itrp_FP_GENN[i,:200,:200]\n",
    "    nrmse_OI[i]      =  (np.sqrt(np.nanmean(((gt-np.nanmean(gt))-(OI-np.nanmean(OI)))**2)))/np.nanstd(gt)\n",
    "    nrmse_FP_GENN[i] =  (np.sqrt(np.nanmean(((gt-np.nanmean(gt))-(FP_GENN-np.nanmean(FP_GENN)))**2)))/np.nanstd(gt)\n",
    "    \n",
    "# plot nRMSE time series\n",
    "N=len(GT)\n",
    "plt.plot(range(N),nrmse_OI,linestyle='solid',color='red',linewidth=2,label=r\"$OI$\")\n",
    "plt.plot(range(N),nrmse_FP_GENN,linestyle='solid',color='seagreen',linewidth=1,label=r\"$FP_GENN$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot averaged normalize error RAPS \n",
    "f0, Pf_OI        = avg_err_raPsd2dv1(itrp_OI[:,:200,:200],GT[:,:200,:200],4,True)\n",
    "f1, Pf_FP_GENN   = avg_err_raPsd2dv1(itrp_FP_GENN[:,:200,:200],GT[:,:200,:200],4,True)\n",
    "wf0 = 1/f0\n",
    "wf1 = 1/f1\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(wf0[1:],Pf_OI[1:],linestyle='solid',color='red',linewidth=.5,label='OI')\n",
    "ax.plot(wf1[1:],Pf_FP_GENN[1:],linestyle='solid',color='seagreen',linewidth=.5,label='FP-GENN')\n",
    "ax.set_xlabel(\"Wavenumber\", fontweight='bold')\n",
    "ax.set_ylabel(\"Power spectral density (m2/(cy/km))\", fontweight='bold')\n",
    "ax.set_xscale('log') ; ax.set_yscale('log')\n",
    "plt.legend(loc='best',prop=dict(size='small'),frameon=False)\n",
    "plt.xticks([50, 100, 200, 500, 1000], [\"50km\", \"100km\", \"200km\", \"500km\", \"1000km\"])\n",
    "ax.invert_xaxis()\n",
    "plt.grid(which='both', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
